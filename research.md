---
layout: page
title:  "Research projects"
---
The following is a list of research projects that I am currently working on. If you wish to collaborate, feel free to reach out on Linkedin or consider making a pull request in the associated github repo.

# Current research projects

- <b>Synthetic Business Process Simulation (SBPS) framework</b>
    - <b>Motivation:</b> Providing a simulation engine for robustness assessment of prediction models for predictive process monitoring. 
    - <b>Status:</b> Paper under review in 'Simulation'
    - <b>Github repo:</b> https://github.com/Mikeriess/SBPS_framework
    
- <b>Loyalty-based queue prioritization</b>
    - <b>Motivation:</b> Improving customer loyalty through prescriptive process monitoring (queue management)
    - <b>Status:</b> Paper written, looking for a suitable journal
    - <b>Github repo:</b> https://github.com/Mikeriess/P3_queue_prioritization

- <b>Danish music producer expert questions and answers</b>
    - <b>Motivation:</b> To compile a dataset for fine-tuning of LLMs using questions and answers from experienced musicians and producers.
    - <b>Status:</b> Work in progress
    - <b>Github repo:</b> https://github.com/Mikeriess/nlp_lydmaskinen 

# Research ideas

- <b>Customer service calls</b>
    - <b>Motivation:</b> Data has been aquired, and an initial brainstorm meeting will be hosted in August.
    - <b>Status:</b> Brainstorm phase
    - <b>Github repo:</b> TBA

- <b>Memory and remaining time predictions</b>
    - <b>Motivation:</b> 
        - A recent paper (https://arxiv.org/abs//2307.03172) found that transformers were less potent at remembering things in the middle of a sequence, compared to the beginning or the end of it. 
        - RNNs should be better at remembering recent information, but worse at the early information.
        - Comparing the two, there might be a performance difference from the earliness perspective. 
    - <b>Status:</b> Brainstorm phase
    - <b>Github repo:</b> TBA